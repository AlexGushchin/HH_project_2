# Проект 2. Анализ вакансий из HeadHunter
## Оглавление
1. [Описание проекта](#1-описание-проекта)
2. [Какой кейс решаем](#2-какой-кейс-решаем)
3. [Краткая информация о данных](#3-краткая-информация-о-данных)
4. [Этапы работы над проектом](#4-этапы-работы-над-проектом)
5. [Результат](#5-результат)
6. [Выводы](#6-выводы)

### 1. Описание проекта
Исследование и анализ данных в базе вакансий для IT-специалистов, состоящей из пяти таблиц, с целью их использования в будущем для создания модели машинного обучения, которая будет рекомендовать вакансии клиентам кадрового агентства, претендующим на позицию Data Scientist.

### 2. Какой кейс решаем
Наша задача - изучить и проанализировать выборку вакансий для IT-специалистов и набор сопутствующих баз данных с целью использования в будущем для создания модели машинного обучения, которая будет рекомендовать вакансии клиентам кадрового агентства, претендующим на позицию Data Scientist.

**Условия:**
* Решение должно быть представлено в шаблоне Jupiter Notebook.
* Результаты должны быть выложены на GitHub.

**Что практикуем:**
* Написание SQL-запросов (postgres).
* Исследование структуры баз данных.
* Исследование зависимостей данных.
* Оформление проекта, создание файла README.
* Синхронизация репозитория с GitHub.
* Тренировка написания кода Python и соблюдение стандартов PEP-8.

### 3. Краткая информация о данных
Данные представляют собой 5 баз данных. Первая с данными о вакансиях, включающая 49197 позиции. Вторая содержит информацию о работодателях (23501 компании). Третья база включает в себя данные о регионах (1362 объекта). Четвертая содержит информацию об отраслях (294 отрасли / сферы деятельности), а при помощи пятой базы данных определяется отраслевая принадлежность работодателей.
Данные для подключения к базам данных были предоставлены SkillFactory и по условиям задания при размещении ноутбука на GitHub были удалены из соответствующей ячейки.

### 4. Этапы работы над проектом
* Этап 1. Предварительный анализ данных.
* Этап 2. Детальный анализ вакансий.
* Этап 3. Анализ работодателей.
* Этап 4. Предметный анализ.
* Этап 5. Дополнительные запросы и итоговый вывод
* Этап 6. Создание README с описанием проекта и размещение результатов на GitHub.

### 5. Результат
Изучена и проанализирована информация в исходных базах данных, сделаны выводы о применимости этой информации для дальнейшей работы над созданием модели, рекомендующей вакансии клиентам кадрового агентства, претендующим на позицию Data Scientist.

### 6. Выводы
Главный вывод по проекту заключается в том, что при дальнейшей работе с этой информацией над моделью, рекомендующей вакансии клиентам кадрового агентства, претендующим на позицию Data Scientist, мы можем столкнуться с недостатком данных. Дело в том, что вакансии Data Scientist занимает очень маленькую долю во всей выборке, при этом вакансии Data Scientist редко содержат инфомацию о возможной зарплате, а зарплата, скорее всего, будет одним из ключевых факторов модели.

В рамках выполнения проекта получилось отработали навык SQL-запросов, который будет в дальнейшем необходим для подгрузки необходимой информации для анализа.